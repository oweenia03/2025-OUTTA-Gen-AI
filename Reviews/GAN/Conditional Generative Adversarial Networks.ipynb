{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XOow3xO4vN1Q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader\n","from IPython import get_ipython\n","from IPython.display import Image as IPImage, display\n","import matplotlib.pyplot as plt\n","\n","\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35chdSmIvcvT"},"outputs":[],"source":["data_dir = './data'\n","os.makedirs(data_dir, exist_ok=True)\n","\n","image_dir = 'images'\n","os.makedirs(image_dir, exist_ok=True) #Create the images directory if it does not exist, and proceed without error if it does exist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OthL_Jdfvd3t"},"outputs":[],"source":["params = {\n","    'num_classes': 10,\n","    'latent_space': 100,\n","    'input_size': (1,32,32),\n","    'image_size': 32,\n","    'lr': 2e-4,\n","    'b1': 0.5,\n","    'b2': 0.999,\n","    'epochs': 100,\n","    'batch_size': 64,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MnCUFZxvfVW"},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.ToTensor(), # Convert image to tensor\n","    transforms.Resize(params['image_size']), # Resizes the image to the specified size\n","    transforms.Normalize([0.5],[0.5]), # Normalizes image with mean and std\n","    ])\n","\n","\"\"\"\n","Args:\n","    - ToTensor: Converts image to a tensor and normalizes pixel values to [0, 1]\n","    - Resize: Resizes the image to the specified size\n","    - Normalize: Normalizes image with a mean of 0.5 and std of 0.5 for all channels\n","\n","Returns\n","    - train_transform (torchvision.transforms.Compose): The composed transformation function\n","\"\"\"\n","\n","train_dataset = datasets.MNIST(data_dir, train=True, transform=train_transform, download=True)\n","\n","\"\"\"\n","Args:\n","    - data_dir (str): Directory to store the dataset\n","    - train (bool): If True, loads the training set; otherwise loads the test set\n","    - transform (callable): Transformation function to apply to the images\n","    - download (bool): If True, downloads the dataset if not found locally\n","\n","Returns:\n","    - train_dataset (torchvision.datasets.MNIST): The MNIST dataset\n","\"\"\"\n","\n","train_dataloader = DataLoader(train_dataset, params['batch_size'], shuffle=True)\n","\n","\"\"\"\n","Args:\n","    - train_dataset (torch.utils.data.Dataset): The dataset to load\n","    - batch_size (int): Number of samples per batch\n","    - shuffle (bool): Whether to shuffle the dataset\n","\n","Returns:\n","    - train_dataloader (torch.utils.data.DataLoader): DataLoader object to iterate over the dataset\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HD4qHI-3vgz7"},"outputs":[],"source":["# Conditional GAN Generator\n","\n","class Generator(nn.Module):\n","\n","   \"\"\"\n","   Generator for CGAN.\n","\n","   Args:\n","       params (dict): Dictionary of model paramets with keys:\n","       - num_classes (int): Number of classes for label embedding.\n","       - latent_space (int): Dimensionality of the noise vector.\n","       - input_size (tuple): Shape of the generated image (channels, height, width)\n","\n","   Returns:\n","       torch.Tensor: Generated Images of shape(batch_size, *input_size)\n","\n","   Example:\n","       >>> params = {'num_classes': 10, 'latent_space': 100, 'input_size': (1, 32, 32)}\n","       >>> generator = Generator(params)\n","       >>> noise = torch.randn(16, 100)\n","       >>> labels = torch.randint(0, 10, (16,))\n","       >>> generated_images = generator(noise, labels)\n","       >>> print(generated_images.shape)  # torch.Size([16, 1, 32, 32])\n","   \"\"\"\n","\n","    def __init__(self, params):\n","        super().__init__()\n","        self.num_classes = params['num_classes']\n","        self.latent_dim = params['latent_space']\n","        self.input_size = params['input_size']\n","\n","        # Label embedding matrix\n","        self.label_emb = nn.Embedding(self.num_classes, self.num_classes)\n","\n","        # Generator Model\n","        self.model = nn.Sequential(\n","            *self.block(self.latent_dim + self.num_classes, 128, normalize=False),\n","            *self.block(128,256),\n","            *self.block(256,512),\n","            *self.block(512,1024),\n","            nn.Linear(1024, int(np.prod(self.input_size))), # last fully connected layer\n","            nn.Tanh() # output: [-1, 1]\n","        )\n","\n","    def block(self, in_channels, out_channels, normalize=True):\n","\n","        \"\"\"\n","        Defines a block consisting of a fully connected layer, optional batch normalization, and a LeakyReLU activation function.\n","\n","        Args:\n","            in_channels (int): Number of input channels.\n","            out_channels (int): Number of output channels.\n","            normalize (bool, optional): Whether to apply Batch Normalization (default=True).\n","\n","        Returns:\n","            list: A list containing the layers of the block, including Linear, BatchNorm1d (if normalize=True),\n","            and LeakyReLU activation functions.\n","        \"\"\"\n","\n","        layers = []\n","        layers.append(nn.Linear(in_channels, out_channels)) # fc layer\n","        if normalize:\n","            layers.append(nn.BatchNorm1d(out_channels, 0.8)) # Batch Normalization\n","        layers.append(nn.LeakyReLU(0.2)) # LeakyReLU\n","        return layers\n","\n","    def forward(self, noise, labels):\n","\n","        \"\"\"\n","        Forward pass of the Generator. Concatenates the label embedding with the noise and\n","        passes it through the model to generate an image.\n","\n","        Args:\n","            noise (torch.Tensor): Input noise vector of shape (batch_size, latent_dim).\n","            labels (torch.Tensor): Input labels of shape (batch_size,).\n","\n","        Returns:\n","            torch.Tensor: Generated image of shape (batch_size, channels, height, width).\n","        \"\"\"\n","\n","        # Concatenate label embedding and image to produce input\n","        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n","        img = self.model(gen_input)\n","        img = img.view(img.size(0), *self.input_size)\n","        return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTziCReevitN"},"outputs":[],"source":["# Conditional GAN Discriminator\n","\n","class Discriminator(nn.Module):\n","\n","    \"\"\"\n","    Discriminator for CGAN.\n","\n","    Args:\n","        params (dict): Dictionary of model parameters with keys:\n","            - num_classes (int): Number of classes for label embedding.\n","            - input_size (tuple): Shape of the input image (channels, height, width).\n","\n","    Returns:\n","        torch.Tensor: Validity scores of shape (batch_size, 1).\n","\n","    Example:\n","        >>> params = {'num_classes': 10, 'input_size': (1, 32, 32)}\n","        >>> discriminator = Discriminator(params)\n","        >>> images = torch.randn(16, 1, 32, 32)\n","        >>> labels = torch.randint(0, 10, (16,))\n","        >>> validity = discriminator(images, labels)\n","        >>> print(validity.shape)  # torch.Size([16, 1])\n","    \"\"\"\n","\n","    def __init__(self,params):\n","        super().__init__()\n","        self.num_classes = params['num_classes']\n","        self.input_size = params['input_size']\n","\n","        # Label embedding matrix\n","        self.label_emb = nn.Embedding(self.num_classes, self.num_classes)\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(self.num_classes + int(np.prod(self.input_size)), 512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(512, 512),\n","            nn.Dropout(0.4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(512, 512),\n","            nn.Dropout(0.4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(512, 1), # Final fc layer, output: 0 or 1\n","        )\n","\n","    def forward(self, img, labels):\n","        \"\"\"\n","        Forward pass of the Discriminator. Concatenates the label embedding with the image\n","        and passes it through the model to predict whether the image is real or fake.\n","\n","        Args:\n","            img (torch.Tensor): Input image of shape (batch_size, channels, height, width).\n","            labels (torch.Tensor): Input labels of shape (batch_size,).\n","\n","        Returns:\n","            torch.Tensor: Validity score of shape (batch_size, 1) indicating whether the image is real or fake.\n","        \"\"\"\n","\n","        # Concatenate label embedding and image to produce input\n","        dis_input = torch.cat((img.view(img.size(0), -1), self.label_emb(labels)), -1)\n","        validity = self.model(dis_input)\n","        return validity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBZRlSXLvkgi"},"outputs":[],"source":["# Loss function\n","adversarial_loss = torch.nn.MSELoss() # Minimize the discriminate probability difference between true image and false image.\n","\n","\"\"\"\n","Args:\n","    - input (torch.Tensor): The predicted values from the model\n","    - target (torch.Tensor): The true labels or ground truth\n","\n","Returns:\n","    - loss (torch.Tensor): The computed loss value\n","\"\"\"\n","\n","# Initialize generator and discriminator\n","generator = Generator(params)\n","discriminator = Discriminator(params)\n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=params['lr'], betas=(params['b1'], params['b2']))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=params['lr'], betas=(params['b1'], params['b2']))\n","\n","\"\"\"\n","Args:\n","    - params (iterable): The parameters of the model to optimize\n","    - lr (float): Learning rate, controls how much the model weights are adjusted at each step\n","    - betas (tuple): Beta values to control momentums (default: (0.5, 0.999))\n","\n","Returns:\n","    - optimizer_G (torch.optim.Adam): The Adam optimizer for the generator\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Whjcnu4xvmTD"},"outputs":[],"source":["# Sample Image\n","\n","def sample_image(n_row, batches_done):\n","\n","    \"\"\"\n","    Saves and optionally displays a grid of generated images.\n","\n","    Args:\n","        n_row (int): Number of rows/columns in the grid of images.\n","        batches_done (int): Identifier for the batch (used for saving file name).\n","\n","    Returns:\n","        None(store image and print).\n","    \"\"\"\n","\n","    # Sample noise\n","    z = torch.randn(n_row ** 2, params['latent_space'])\n","    # Get labels ranging from 0 to n_classes for n rows\n","    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n","    labels = torch.tensor(labels)\n","    gen_imgs = generator(z, labels)\n","    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n","\n","     # Save the image\n","    file_path = f\"images/{batches_done}.png\"\n","    save_image(gen_imgs.data, file_path, nrow=n_row, normalize=True)\n","\n","    # Display the image in Colab\n","    display(IPImage(file_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Mw5ZNw5Bak2lrECdkEljD9oggmSI8P5a"},"id":"yjcKCfV6voQw","outputId":"c32476b4-4e85-4c36-9a7d-b16f1a9e3cc2"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["batch_count = 0\n","\n","for epoch in tqdm(range(params['epochs'])):\n","    for i, (imgs, labels) in enumerate(train_dataloader):\n","        \"\"\"\n","        Args:\n","            epoch(int): The curren epoch number in the training process.\n","            imgs(torch.Tensor): A batch of input images with shape (batch_size, channels, height, width).\n","            labels(torch.Tensor): A batch of unput labels with shape (batch_size,).\n","            z(torch.Tensor): The noise vector used as input to the Generator, with shape (batch_size, latent_space).\n","            gen_labels(torch.Tensor): The labels for the generated images, with shape(batch_size,).\n","            valid(torch.Tensor): The target values for real images, typically filled with 1.0, indicating 'real' images.\n","            fake(torch.Tensor): The target values for generated (fake) images, typically filled with 0.0, indicating 'fake' images.\n","\n","        Returns:\n","            None(Update Generator and Discriminator every batch while training)\n","        \"\"\"\n","\n","        # Adversarial ground truths\n","        valid = torch.Tensor(imgs.size(0), 1).fill_(1.0).to(device)\n","        fake = torch.Tensor(imgs.size(0), 1).fill_(0.0).to(device)\n","\n","        real_imgs = imgs.to(device)\n","        real_labels = labels.to(device)\n","\n","        # Train Generator\n","        optimizer_G.zero_grad()\n","\n","        # Sample noise as Generator input\n","        z = torch.randn(imgs.size(0), params['latent_space']).to(device)\n","        gen_labels = torch.randint(0, params['num_classes'], (imgs.size(0),)).to(device)\n","\n","        # Generate a batch of images\n","        gen_imgs = generator(z, gen_labels)\n","\n","        # Loss measure Generator's ability to fool the discriminator\n","        validity = discriminator(gen_imgs, gen_labels)\n","        g_loss = adversarial_loss(validity, valid)\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        # Train Discriminator\n","        optimizer_D.zero_grad()\n","\n","        # Measure discriminator's ability to classify real from generated samples\n","        real_loss = adversarial_loss(discriminator(real_imgs, real_labels), valid)\n","        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), labels), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        \"\"\"\n","        Generator Loss:\n","          - The loss is the Binary Cross-Entropy loss between the Discriminator's output for the generated images and the target label '1'.\n","          - The Generator loss encourages it to produce images that are more likely to be classified as real by the Discriminator.\n","        Discriminator Loss:\n","          - The total loss is the sum of:\n","            - 'real_loss': Binary Cross-Entropy loss for real images.\n","            - 'fake_loss': Binary Cross-Entropy loss for generated images.\n","          - The Discriminator loss encourages it to output a high value for real images and a low value for fake images.\n","        \"\"\"\n","\n","        batches_done = epoch * len(train_dataloader) + i\n","        if batches_done % 1000 == 0:\n","            print(\n","                \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n","                % (epoch, params['epochs'], d_loss.item(), g_loss.item())\n","            )\n","            sample_image(n_row=10, batches_done=batches_done)\n","\n","      \"\"\"\n","      About Result:\n","         Discriminator Loss: If loss is close to 0, discriminator is classifying well.\n","         Generator Loss: Generator is generating better images. Especially G loss is stable in certain range,\n","                         Generator is generating good quality images consistently.\n","      \"\"\"\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPs9ZdtWhixGaQE6t2qj2VB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
